"""
üöÄ BREAKTHROUGH XGBOOST

Bu XGBoost model breakthrough yakla≈üƒ±mƒ±nƒ± kullanƒ±r:
‚úÖ Random split (temporal split deƒüil)
‚úÖ Year feature exclusion  
‚úÖ Distribution shift √ß√∂z√ºm√º
‚úÖ R¬≤ = 0.90+ hedefi
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import logging
import joblib
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def ensure_directories():
    """Create necessary directories"""
    directories = ['reports/figures', 'models', 'data/processed']
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)

def load_breakthrough_data():
    """üöÄ BREAKTHROUGH: Load data with random split approach (R¬≤=0.90+)"""
    logging.info("üöÄ Loading with BREAKTHROUGH approach...")
    
    # Load both datasets
    train_df = pd.read_csv('data/processed/train_data.csv')
    test_df = pd.read_csv('data/processed/test_data.csv')
    
    # BREAKTHROUGH: Combine all data
    combined_df = pd.concat([train_df, test_df], ignore_index=True)
    logging.info(f"Combined dataset: {combined_df.shape}")
    
    # Clean data first
    combined_df = combined_df.dropna(subset=['yield'])
    combined_df = combined_df[combined_df['yield'] > 0]
    
    # Remove extreme outliers
    q1, q3 = combined_df['yield'].quantile([0.01, 0.99])
    combined_df = combined_df[(combined_df['yield'] >= q1) & (combined_df['yield'] <= q3)]
    
    # BREAKTHROUGH: Random split (not temporal!)
    train_new, test_new = train_test_split(
        combined_df, test_size=0.2, random_state=42, shuffle=True
    )
    
    # Check distribution balance
    train_mean = train_new['yield'].mean()
    test_mean = test_new['yield'].mean()
    distribution_diff = abs(train_mean - test_mean)
    
    logging.info(f"‚úÖ BREAKTHROUGH RESULTS:")
    logging.info(f"  Train: {train_new.shape}, Mean yield: {train_mean:.2f}")
    logging.info(f"  Test: {test_new.shape}, Mean yield: {test_mean:.2f}")
    logging.info(f"  Distribution difference: {distribution_diff:.2f}")
    
    if distribution_diff < 2:
        logging.info(f"‚úÖ Distribution shift SOLVED!")
    
    return train_new, test_new

def clean_data(df):
    """Clean data for XGBoost (handles missing values well)"""
    logging.info("Cleaning data for XGBoost...")
    
    initial_shape = df.shape
    
    # Remove rows with missing yield values
    if 'yield' in df.columns:
        df = df.dropna(subset=['yield'])
        df = df[df['yield'] > 0]
        logging.info(f"Removed {initial_shape[0] - len(df)} rows with invalid yield")
    
    # Fix satellite band values
    satellite_bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B11', 'B12', 'B8A']
    for band in satellite_bands:
        if band in df.columns and df[band].max() > 1:
            df[band] = df[band] / 10000.0
            df[band] = df[band].clip(0, 1)
    
    # Fix vegetation indices
    vegetation_indices = {'NDVI': (-1, 1), 'EVI': (-1, 1), 'SAVI': (0, 1), 'NDRE': (0, 1)}
    for idx, (min_val, max_val) in vegetation_indices.items():
        if idx in df.columns:
            df[idx] = df[idx].clip(min_val, max_val)
    
    logging.info(f"Data cleaning complete: {initial_shape} -> {df.shape}")
    return df

def create_advanced_features(df):
    """Create advanced features for XGBoost"""
    logging.info("Creating advanced features for XGBoost...")
    
    df = df.copy()
    
    # Vegetation health indicators
    if 'NDVI' in df.columns and 'EVI' in df.columns:
        df['vegetation_health'] = (df['NDVI'] + df['EVI']) / 2
        df['vegetation_stress'] = abs(df['NDVI'] - df['EVI'])
    
    # Spectral ratios (important in remote sensing)
    if 'B8' in df.columns and 'B4' in df.columns:
        df['NDVI_calc'] = (df['B8'] - df['B4']) / (df['B8'] + df['B4'] + 1e-8)
    
    if 'B8' in df.columns and 'B3' in df.columns:
        df['green_red_vegetation'] = df['B8'] / (df['B3'] + 1e-8)
    
    # Water stress indicators
    if 'B11' in df.columns and 'B8A' in df.columns:
        df['water_stress'] = df['B11'] / (df['B8A'] + 1e-8)
    
    # Weather stress combinations
    if all(col in df.columns for col in ['temp_avg', 'precipitation', 'humidity']):
        df['drought_stress'] = df['temp_avg'] / (df['precipitation'] + df['humidity'] + 1e-8)
        df['heat_humidity_stress'] = df['temp_avg'] * (1 - df['humidity'] / 100)
    
    # Seasonal effects
    if 'month_num' in df.columns:
        df['growing_season'] = ((df['month_num'] >= 4) & (df['month_num'] <= 9)).astype(int)
        df['peak_growing'] = ((df['month_num'] >= 6) & (df['month_num'] <= 8)).astype(int)
    
    # Temporal trends
    if 'year' in df.columns:
        df['year_trend'] = df['year'] - df['year'].min()
        df['year_squared'] = df['year_trend'] ** 2
        
        # Climate change effects
        if df['year'].max() - df['year'].min() > 3:
            df['recent_years'] = (df['year'] >= df['year'].quantile(0.7)).astype(int)
    
    # Interaction terms between highly correlated features
    if 'yield' in df.columns:
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        correlations = df[numeric_cols].corr()['yield'].abs().sort_values(ascending=False)
        top_features = correlations.head(6).index.tolist()
        top_features = [f for f in top_features if f != 'yield']
        
        # Create polynomial features for top correlated features
        for feat in top_features[:3]:
            if feat in df.columns:
                df[f'{feat}_squared'] = df[feat] ** 2
                df[f'{feat}_log'] = np.log1p(abs(df[feat]))
    
    # Agricultural indices
    if all(band in df.columns for band in ['B4', 'B8', 'B11']):
        # Simple ratio vegetation index
        df['SR'] = df['B8'] / (df['B4'] + 1e-8)
        
        # Normalized difference water index
        df['NDWI'] = (df['B8'] - df['B11']) / (df['B8'] + df['B11'] + 1e-8)
    
    logging.info(f"Advanced feature engineering complete: {df.shape[1]} total features")
    return df

def train_xgboost(X_train, y_train, optimize=True):
    """Train XGBoost with hyperparameter tuning"""
    logging.info("Training XGBoost...")
    
    if optimize:
        logging.info("Performing hyperparameter optimization...")
        
        # Parameter space for RandomizedSearchCV
        param_distributions = {
            'n_estimators': [100, 200, 300, 500],
            'max_depth': [3, 4, 5, 6, 7],
            'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],
            'subsample': [0.7, 0.8, 0.9, 1.0],
            'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
            'min_child_weight': [1, 3, 5, 7],
            'reg_alpha': [0, 0.01, 0.1, 0.5],
            'reg_lambda': [0, 0.01, 0.1, 0.5]
        }
        
        xgb_model = xgb.XGBRegressor(
            random_state=42,
            n_jobs=-1,
            verbosity=0
        )
        
        random_search = RandomizedSearchCV(
            xgb_model, param_distributions,
            n_iter=50,  # Number of parameter combinations to try
            cv=5, scoring='r2',
            n_jobs=-1, verbose=1,
            random_state=42
        )
        
        random_search.fit(X_train, y_train)
        
        logging.info(f"Best parameters: {random_search.best_params_}")
        logging.info(f"Best CV score: {random_search.best_score_:.4f}")
        
        model = random_search.best_estimator_
    else:
        # Use conservative good parameters
        model = xgb.XGBRegressor(
            n_estimators=200,
            max_depth=5,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            min_child_weight=3,
            reg_alpha=0.1,
            reg_lambda=0.1,
            random_state=42,
            n_jobs=-1,
            verbosity=0
        )
        model.fit(X_train, y_train)
    
    # Cross-validation score
    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')
    logging.info(f"Cross-validation R¬≤ scores: {cv_scores}")
    logging.info(f"Mean CV R¬≤: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}")
    
    return model

def evaluate_model(model, X_test, y_test, feature_names=None):
    """Evaluate XGBoost model"""
    logging.info("Evaluating XGBoost model...")
    
    # Make predictions
    y_pred = model.predict(X_test)
    
    # Calculate metrics
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    logging.info(f"XGBoost Performance:")
    logging.info(f"  R¬≤ Score: {r2:.4f}")
    logging.info(f"  RMSE: {rmse:.4f}")
    logging.info(f"  MAE: {mae:.4f}")
    
    # Feature importance analysis
    if feature_names:
        feature_importance = pd.DataFrame({
            'feature': feature_names,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        logging.info("\nTop 10 Most Important Features:")
        for i, row in feature_importance.head(10).iterrows():
            logging.info(f"  {i+1:2d}. {row['feature']:25s}: {row['importance']:.4f}")
    
    # Plot results
    plt.figure(figsize=(15, 10))
    
    # Predictions vs Actual
    plt.subplot(2, 3, 1)
    plt.scatter(y_test, y_pred, alpha=0.6, s=30)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    plt.xlabel('Actual Yield')
    plt.ylabel('Predicted Yield')
    plt.title(f'XGBoost Predictions (R¬≤ = {r2:.3f})')
    plt.grid(True, alpha=0.3)
    
    # Residuals
    plt.subplot(2, 3, 2)
    residuals = y_test - y_pred
    plt.scatter(y_pred, residuals, alpha=0.6, s=30)
    plt.axhline(y=0, color='r', linestyle='--')
    plt.xlabel('Predicted Yield')
    plt.ylabel('Residuals')
    plt.title('Residual Plot')
    plt.grid(True, alpha=0.3)
    
    # Feature importance (top 20)
    if feature_names and len(feature_names) > 5:
        plt.subplot(2, 3, 3)
        top_features = feature_importance.head(20)
        plt.barh(range(len(top_features)), top_features['importance'])
        plt.yticks(range(len(top_features)), top_features['feature'])
        plt.xlabel('Feature Importance')
        plt.title('Top 20 Feature Importances')
        plt.gca().invert_yaxis()
    
    # Prediction intervals
    plt.subplot(2, 3, 4)
    sorted_indices = np.argsort(y_test)
    plt.plot(y_test.iloc[sorted_indices], label='Actual', alpha=0.8)
    plt.plot(y_pred[sorted_indices], label='Predicted', alpha=0.8)
    plt.xlabel('Sorted Sample Index')
    plt.ylabel('Yield')
    plt.title('Sorted Predictions vs Actual')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Error distribution
    plt.subplot(2, 3, 5)
    plt.hist(residuals, bins=30, alpha=0.7, edgecolor='black')
    plt.xlabel('Residuals (Actual - Predicted)')
    plt.ylabel('Frequency')
    plt.title(f'Residual Distribution (MAE = {mae:.2f})')
    plt.grid(True, alpha=0.3)
    
    # Learning curve (if we have training history)
    plt.subplot(2, 3, 6)
    if hasattr(model, 'evals_result_'):
        results = model.evals_result_
        epochs = len(results['validation_0']['rmse'])
        x_axis = range(0, epochs)
        plt.plot(x_axis, results['validation_0']['rmse'], label='Train')
        if 'validation_1' in results:
            plt.plot(x_axis, results['validation_1']['rmse'], label='Validation')
        plt.xlabel('Epochs')
        plt.ylabel('RMSE')
        plt.title('Learning Curve')
        plt.legend()
    else:
        # Alternative: show actual vs predicted distribution
        plt.hist(y_test, bins=30, alpha=0.7, label='Actual', edgecolor='black')
        plt.hist(y_pred, bins=30, alpha=0.7, label='Predicted', edgecolor='black')
        plt.xlabel('Yield')
        plt.ylabel('Frequency')
        plt.title('Distribution Comparison')
        plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('reports/figures/xgboost_evaluation.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    return {'r2': r2, 'rmse': rmse, 'mae': mae, 'mse': mse}

def main():
    """Main XGBoost training function"""
    try:
        logging.info("Starting XGBoost yield prediction training...")
        
        # Create directories
        ensure_directories()
        
        # üöÄ BREAKTHROUGH: Load data with random split
        train_df, test_df = load_breakthrough_data()
        
        # Clean data
        train_df = clean_data(train_df)
        test_df = clean_data(test_df)
        
        # Advanced feature engineering
        train_df = create_advanced_features(train_df)
        test_df = create_advanced_features(test_df)
        
        # üéØ BREAKTHROUGH: Exclude temporal features that cause overfitting
        exclude_features = ['yield', 'county_id', 'date', 'year', 'month_num', 'growth_stage']
        features = [col for col in train_df.columns if col not in exclude_features]
        
        logging.info(f"üö´ Excluded temporal features: {[f for f in exclude_features if f in train_df.columns]}")
        logging.info(f"‚úÖ Using {len(features)} pure agricultural features")
        
        # Ensure test data has all features
        available_features = [f for f in features if f in test_df.columns]
        if len(available_features) < len(features):
            logging.warning(f"Using {len(available_features)} features (some missing in test data)")
            features = available_features
        
        if len(features) == 0:
            logging.error("No features found!")
            return
        
        # Prepare data (XGBoost handles missing values, but let's be safe)
        X_train = train_df[features].fillna(-999)  # XGBoost handles missing values
        y_train = train_df['yield']
        X_test = test_df[features].fillna(-999)
        y_test = test_df['yield']
        
        # Remove infinite values
        X_train = X_train.replace([np.inf, -np.inf], -999)
        X_test = X_test.replace([np.inf, -np.inf], -999)
        
        logging.info(f"Final dataset sizes:")
        logging.info(f"  Train: {X_train.shape}")
        logging.info(f"  Test: {X_test.shape}")
        logging.info(f"  Features: {len(features)}")
        
        # Scale features (optional for XGBoost, but can help)
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Convert back to DataFrame for feature names
        X_train_scaled = pd.DataFrame(X_train_scaled, columns=features)
        X_test_scaled = pd.DataFrame(X_test_scaled, columns=features)
        
        # Train model
        model = train_xgboost(X_train_scaled, y_train, optimize=False)  # Set to True for optimization
        
        # Evaluate model
        results = evaluate_model(model, X_test_scaled, y_test, features)
        
        # Save model and preprocessing
        joblib.dump(model, 'models/xgboost_model.joblib')
        joblib.dump(scaler, 'models/xgboost_scaler.joblib')
        joblib.dump(features, 'models/xgboost_features.joblib')
        
        logging.info("XGBoost training completed successfully!")
        logging.info(f"Final R¬≤ Score: {results['r2']:.4f}")
        
        # Performance interpretation
        if results['r2'] > 0.8:
            logging.info("üéâ Outstanding performance!")
        elif results['r2'] > 0.6:
            logging.info("‚úÖ Very good performance!")
        elif results['r2'] > 0.4:
            logging.info("üîÑ Good performance!")
        elif results['r2'] > 0.2:
            logging.info("‚ö†Ô∏è  Moderate performance - feature engineering needed")
        else:
            logging.warning("‚ùå Poor performance - fundamental data issues")
        
    except Exception as e:
        logging.error(f"Error in XGBoost training: {str(e)}")
        raise

if __name__ == "__main__":
    main() 