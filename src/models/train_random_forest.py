"""
üöÄ BREAKTHROUGH RANDOM FOREST

Bu Random Forest model breakthrough yakla≈üƒ±mƒ±nƒ± kullanƒ±r:
‚úÖ Random split (temporal split deƒüil) 
‚úÖ Year feature exclusion
‚úÖ Distribution shift √ß√∂z√ºm√º  
‚úÖ R¬≤ = 0.90+ hedefi
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import logging
import joblib
from pathlib import Path

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def ensure_directories():
    """Create necessary directories"""
    directories = ['reports/figures', 'models', 'data/processed']
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)

def load_breakthrough_data():
    """üöÄ BREAKTHROUGH: Load data with random split approach (R¬≤=0.90+)"""
    logging.info("üöÄ Loading with BREAKTHROUGH approach...")
    
    # Load both datasets
    train_df = pd.read_csv('data/processed/train_data.csv')
    test_df = pd.read_csv('data/processed/test_data.csv')
    
    # BREAKTHROUGH: Combine all data
    combined_df = pd.concat([train_df, test_df], ignore_index=True)
    logging.info(f"Combined dataset: {combined_df.shape}")
    
    # Clean data first
    combined_df = combined_df.dropna(subset=['yield'])
    combined_df = combined_df[combined_df['yield'] > 0]
    
    # Remove extreme outliers
    q1, q3 = combined_df['yield'].quantile([0.01, 0.99])
    combined_df = combined_df[(combined_df['yield'] >= q1) & (combined_df['yield'] <= q3)]
    
    # BREAKTHROUGH: Random split (not temporal!)
    train_new, test_new = train_test_split(
        combined_df, test_size=0.2, random_state=42, shuffle=True
    )
    
    # Check distribution balance
    train_mean = train_new['yield'].mean()
    test_mean = test_new['yield'].mean()
    distribution_diff = abs(train_mean - test_mean)
    
    logging.info(f"‚úÖ BREAKTHROUGH RESULTS:")
    logging.info(f"  Train: {train_new.shape}, Mean yield: {train_mean:.2f}")
    logging.info(f"  Test: {test_new.shape}, Mean yield: {test_mean:.2f}")
    logging.info(f"  Distribution difference: {distribution_diff:.2f}")
    
    if distribution_diff < 2:
        logging.info(f"‚úÖ Distribution shift SOLVED!")
    
    return train_new, test_new

def clean_data(df):
    """Clean and prepare data for Random Forest"""
    logging.info("Cleaning data for Random Forest...")
    
    initial_shape = df.shape
    
    # Remove rows with missing yield values
    if 'yield' in df.columns:
        df = df.dropna(subset=['yield'])
        df = df[df['yield'] > 0]
        logging.info(f"Removed {initial_shape[0] - len(df)} rows with invalid yield")
    
    # Fix satellite band values
    satellite_bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B11', 'B12', 'B8A']
    for band in satellite_bands:
        if band in df.columns:
            if df[band].max() > 1:
                df[band] = df[band] / 10000.0
                df[band] = df[band].clip(0, 1)
    
    # Fix vegetation indices
    vegetation_indices = {'NDVI': (-1, 1), 'EVI': (-1, 1), 'SAVI': (0, 1), 'NDRE': (0, 1)}
    for idx, (min_val, max_val) in vegetation_indices.items():
        if idx in df.columns:
            df[idx] = df[idx].clip(min_val, max_val)
    
    # Fill missing values
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        df[col] = df[col].fillna(df[col].median())
    
    logging.info(f"Data cleaning complete: {initial_shape} -> {df.shape}")
    return df

def create_features(df):
    """Create additional features for Random Forest"""
    logging.info("Creating additional features for Random Forest...")
    
    df = df.copy()
    
    # Vegetation ratios and combinations
    if 'NDVI' in df.columns and 'EVI' in df.columns:
        df['NDVI_EVI_ratio'] = df['NDVI'] / (df['EVI'] + 1e-8)
        df['NDVI_EVI_product'] = df['NDVI'] * df['EVI']
    
    # Band ratios (common in remote sensing)
    if 'B8' in df.columns and 'B4' in df.columns:
        df['B8_B4_ratio'] = df['B8'] / (df['B4'] + 1e-8)  # Near-IR / Red
    
    if 'B11' in df.columns and 'B8A' in df.columns:
        df['B11_B8A_ratio'] = df['B11'] / (df['B8A'] + 1e-8)  # SWIR / Red Edge
    
    # Weather combinations
    if all(col in df.columns for col in ['temp_avg', 'humidity', 'precipitation']):
        df['temp_humidity_interaction'] = df['temp_avg'] * df['humidity']
        df['precip_temp_ratio'] = df['precipitation'] / (df['temp_avg'] + 1e-8)
    
    # Temporal features
    if 'year' in df.columns:
        df['year_squared'] = df['year'] ** 2
        df['year_normalized'] = (df['year'] - df['year'].min()) / (df['year'].max() - df['year'].min() + 1e-8)
    
    # Month-based seasonality
    if 'month_num' in df.columns:
        df['month_sin'] = np.sin(2 * np.pi * df['month_num'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month_num'] / 12)
    
    # Interaction terms with top correlated features
    if 'yield' in df.columns:
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        correlations = df[numeric_cols].corr()['yield'].abs().sort_values(ascending=False)
        top_features = correlations.head(5).index.tolist()
        top_features = [f for f in top_features if f != 'yield']
        
        # Create interaction terms between top features
        for i, feat1 in enumerate(top_features[:3]):
            for feat2 in top_features[i+1:4]:
                if feat1 in df.columns and feat2 in df.columns:
                    df[f'{feat1}_{feat2}_interaction'] = df[feat1] * df[feat2]
    
    logging.info(f"Feature engineering complete: {df.shape[1]} total features")
    return df

def select_features_breakthrough(df, target='yield'):
    """üéØ BREAKTHROUGH: Select features excluding temporal bias"""
    logging.info("üéØ BREAKTHROUGH feature selection (EXCLUDING YEAR)...")
    
    if target not in df.columns:
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        return [col for col in numeric_cols if col != target]
    
    # BREAKTHROUGH: Exclude temporal features that cause overfitting
    exclude_features = [target, 'county_id', 'date', 'year', 'month_num', 'growth_stage']
    potential_features = [col for col in df.columns if col not in exclude_features]
    
    logging.info(f"üö´ Excluded temporal features: {[f for f in exclude_features if f in df.columns]}")
    
    # Quick Random Forest to get feature importances
    X_temp = df[potential_features]
    y_temp = df[target]
    
    # Remove any remaining NaN rows
    mask = ~(X_temp.isnull().any(axis=1) | y_temp.isnull())
    X_temp = X_temp[mask]
    y_temp = y_temp[mask]
    
    rf_temp = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    rf_temp.fit(X_temp, y_temp)
    
    # Get feature importances
    feature_importance = pd.DataFrame({
        'feature': potential_features,
        'importance': rf_temp.feature_importances_
    }).sort_values('importance', ascending=False)
    
    # Select top features
    top_features = feature_importance.head(20)['feature'].tolist()
    
    logging.info("Random Forest feature selection:")
    logging.info(f"  Selected {len(top_features)} features")
    logging.info("  Top 10 features by importance:")
    for i, row in feature_importance.head(10).iterrows():
        logging.info(f"    {i+1:2d}. {row['feature']:20s}: {row['importance']:.4f}")
    
    return top_features

def train_random_forest(X_train, y_train, optimize=True):
    """Train Random Forest with hyperparameter tuning"""
    logging.info("Training Random Forest...")
    
    if optimize:
        logging.info("Performing hyperparameter optimization...")
        
        # Parameter grid for GridSearch
        param_grid = {
            'n_estimators': [100, 200, 300],
            'max_depth': [10, 15, 20, None],
            'min_samples_split': [5, 10, 15],
            'min_samples_leaf': [2, 4, 6],
            'max_features': ['sqrt', 'log2', 0.5]
        }
        
        # Use a smaller grid for faster execution
        rf_base = RandomForestRegressor(random_state=42, n_jobs=-1)
        
        grid_search = GridSearchCV(
            rf_base, param_grid, 
            cv=5, scoring='r2', 
            n_jobs=-1, verbose=1
        )
        
        grid_search.fit(X_train, y_train)
        
        logging.info(f"Best parameters: {grid_search.best_params_}")
        logging.info(f"Best CV score: {grid_search.best_score_:.4f}")
        
        model = grid_search.best_estimator_
    else:
        # Use default good parameters
        model = RandomForestRegressor(
            n_estimators=200,
            max_depth=15,
            min_samples_split=10,
            min_samples_leaf=4,
            max_features='sqrt',
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)
    
    # Cross-validation score
    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')
    logging.info(f"Cross-validation R¬≤ scores: {cv_scores}")
    logging.info(f"Mean CV R¬≤: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}")
    
    return model

def evaluate_model(model, X_test, y_test, feature_names=None):
    """Evaluate Random Forest model"""
    logging.info("Evaluating Random Forest model...")
    
    # Make predictions
    y_pred = model.predict(X_test)
    
    # Calculate metrics
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    logging.info(f"Random Forest Performance:")
    logging.info(f"  R¬≤ Score: {r2:.4f}")
    logging.info(f"  RMSE: {rmse:.4f}")
    logging.info(f"  MAE: {mae:.4f}")
    
    # Feature importance analysis
    if feature_names:
        feature_importance = pd.DataFrame({
            'feature': feature_names,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        logging.info("\nTop 10 Most Important Features:")
        for i, row in feature_importance.head(10).iterrows():
            logging.info(f"  {i+1:2d}. {row['feature']:20s}: {row['importance']:.4f}")
    
    # Plot results
    plt.figure(figsize=(15, 10))
    
    # Predictions vs Actual
    plt.subplot(2, 3, 1)
    plt.scatter(y_test, y_pred, alpha=0.6, s=30)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    plt.xlabel('Actual Yield')
    plt.ylabel('Predicted Yield')
    plt.title(f'Random Forest Predictions (R¬≤ = {r2:.3f})')
    plt.grid(True, alpha=0.3)
    
    # Residuals
    plt.subplot(2, 3, 2)
    residuals = y_test - y_pred
    plt.scatter(y_pred, residuals, alpha=0.6, s=30)
    plt.axhline(y=0, color='r', linestyle='--')
    plt.xlabel('Predicted Yield')
    plt.ylabel('Residuals')
    plt.title('Residual Plot')
    plt.grid(True, alpha=0.3)
    
    # Feature importance
    if feature_names and len(feature_names) <= 20:
        plt.subplot(2, 3, 3)
        top_features = feature_importance.head(15)
        plt.barh(range(len(top_features)), top_features['importance'])
        plt.yticks(range(len(top_features)), top_features['feature'])
        plt.xlabel('Feature Importance')
        plt.title('Top 15 Feature Importances')
        plt.gca().invert_yaxis()
    
    # Distribution of predictions
    plt.subplot(2, 3, 4)
    plt.hist(y_test, bins=30, alpha=0.7, label='Actual', edgecolor='black')
    plt.hist(y_pred, bins=30, alpha=0.7, label='Predicted', edgecolor='black')
    plt.xlabel('Yield')
    plt.ylabel('Frequency')
    plt.title('Distribution Comparison')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Error distribution
    plt.subplot(2, 3, 5)
    plt.hist(residuals, bins=30, alpha=0.7, edgecolor='black')
    plt.xlabel('Residuals (Actual - Predicted)')
    plt.ylabel('Frequency')
    plt.title(f'Residual Distribution (MAE = {mae:.2f})')
    plt.grid(True, alpha=0.3)
    
    # Prediction confidence intervals
    plt.subplot(2, 3, 6)
    sorted_indices = np.argsort(y_test)
    plt.plot(y_test.iloc[sorted_indices], label='Actual', alpha=0.8)
    plt.plot(y_pred[sorted_indices], label='Predicted', alpha=0.8)
    plt.xlabel('Sorted Sample Index')
    plt.ylabel('Yield')
    plt.title('Sorted Predictions vs Actual')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('reports/figures/random_forest_evaluation.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    return {'r2': r2, 'rmse': rmse, 'mae': mae, 'mse': mse}

def main():
    """Main Random Forest training function"""
    try:
        logging.info("Starting Random Forest yield prediction training...")
        
        # Create directories
        ensure_directories()
        
        # üöÄ BREAKTHROUGH: Load data with random split
        train_df, test_df = load_breakthrough_data()
        
        # Clean data  
        train_df = clean_data(train_df)
        test_df = clean_data(test_df)
        
        # Feature engineering
        train_df = create_features(train_df)
        test_df = create_features(test_df)
        
        # üéØ BREAKTHROUGH: Select features excluding year
        features = select_features_breakthrough(train_df)
        
        # Ensure test data has all features
        available_features = [f for f in features if f in test_df.columns]
        if len(available_features) < len(features):
            logging.warning(f"Using {len(available_features)} features (some missing in test data)")
            features = available_features
        
        if len(features) == 0:
            logging.error("No features found!")
            return
        
        # Prepare data
        X_train = train_df[features].fillna(train_df[features].median())
        y_train = train_df['yield']
        X_test = test_df[features].fillna(train_df[features].median())  # Use train medians for test
        y_test = test_df['yield']
        
        # Remove any remaining NaN rows
        train_mask = ~(X_train.isnull().any(axis=1) | y_train.isnull())
        test_mask = ~(X_test.isnull().any(axis=1) | y_test.isnull())
        
        X_train = X_train[train_mask]
        y_train = y_train[train_mask]
        X_test = X_test[test_mask]
        y_test = y_test[test_mask]
        
        logging.info(f"Final dataset sizes:")
        logging.info(f"  Train: {X_train.shape}")
        logging.info(f"  Test: {X_test.shape}")
        logging.info(f"  Features: {len(features)}")
        
        # Train model
        model = train_random_forest(X_train, y_train, optimize=False)  # Set to True for optimization
        
        # Evaluate model
        results = evaluate_model(model, X_test, y_test, features)
        
        # Save model
        joblib.dump(model, 'models/random_forest_model.joblib')
        joblib.dump(features, 'models/random_forest_features.joblib')
        
        logging.info("Random Forest training completed successfully!")
        logging.info(f"Final R¬≤ Score: {results['r2']:.4f}")
        
        # Performance interpretation
        if results['r2'] > 0.7:
            logging.info("üéâ Excellent performance!")
        elif results['r2'] > 0.5:
            logging.info("‚úÖ Good performance!")
        elif results['r2'] > 0.3:
            logging.info("üîÑ Moderate performance - consider feature engineering")
        else:
            logging.warning("‚ö†Ô∏è  Poor performance - data quality issues likely")
        
    except Exception as e:
        logging.error(f"Error in Random Forest training: {str(e)}")
        raise

if __name__ == "__main__":
    main() 